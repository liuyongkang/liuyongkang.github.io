---
layout: post
title: 数据压缩之编码器
description: 主要介绍了常用的两种编码，huffman编码和算术编码
category: blog
tag: ['编码', '压缩', 'huffman', '算术编码']
---

##前言

这一章主要来讲编码器。编码器是一种将信息一种特定格式转换为其他特定格式的算法。当然除了编码器还需要解码器，它会将编码后的数据转换为原数据。

本文主要会讲两个常用的编码，一个是很多人比较熟悉的huffman编码，另一个是算术编码。

##huffman编码

huffman编码是一种最优前缀编码，那么前缀码又是什么呢？

一个字符的编码不是另一个字符编码的前缀，这样的编码就是前缀码，而最优前缀编码就是，编码出的长度最短。

###huffman树

生成huffman编码的过程需要建立一棵huffman树

直接来看一个例子吧，现有如下数据（加空格只是为了看起来方便）：

        abac deaf abea ceba caba feac aaca cb

统计频数如下：

![频数统计结果](/images/数据压缩之编码器/table1.png)

现在开始建树，先从从表中找出两个频数最小的元素，把较大的放左边，较小的放右边，然后把它们的频数加起来，合为一个元素：

![第一步](/images/数据压缩之编码器/table2.png)

新生成的元素与其他同等对待，再次选出两个：

![第二步](/images/数据压缩之编码器/table3.png)

重复上述步骤，直到只剩一个元素，这时树就建立好了

![第三步](/images/数据压缩之编码器/table4.png)
![第四步](/images/数据压缩之编码器/table5.png)
![最后一步](/images/数据压缩之编码器/table6.png)

###生成编码

下一步要根据哈夫曼树得到huffman编码，从huffman树的树根到每个字符的路径就可以作为这个字符的编码。

就以上面的huffman树来举例，假设左代表“0”，右代表“1”，那么我们就可以得到a的编码为“1”，b的编码为“00”

可以得到编码表：

![huffman编码](/images/数据压缩之编码器/huffman_code.png)

将前面的数据编码后的结果就是

        1001 1000 0111 0101 
        0110 1001 0101 0000
        1000 1100 0100 1101 
        1001 0100 0110 0010 
        0000 1 

编码前数据为240bits，编码后只有69bits，看起来效果还不错哦

###范式huffman编码

但在实际使用中，朴素的huffman实现效率很差，后来出现了一个huffman的改进算法，叫做范式huffman编码，实现起来比huffman会好很多。

引用一个很了解底层的牛人原话：

>HUFFMAN主要有两个问题，一是需要扫描两遍输入数据，二是树状结构编解码慢。对于第一个问题，基于统计信息的熵编码都很难解决这个问题，可以设计成自适应的，根据统计数据不停地改变调整码树，这会比较麻烦。对于第二个问题，这跟硬件有关系，二叉树的编码、解码都是O(1)的，复杂度上不能更优了，但是计算机硬件的特性，会使得树状结构遍历过程中CACHE MISS比较严重，如果码树比较小的话，可以都放在一级CACHE，性能会好很多，但是编码、解码一般都只是模块流程的一部分，所以码树经常会挤出CACHE，就算留在CACHE里，树状结构if else也会造成分枝预测错误，导致流水线中断。

原文地址：[http://hi.baidu.com/rodimus/item/3f61e235646950d66c15e9ef][1]

上面的两个问题中，第一个很难避免，这是由于huffman算法本身决定的，而第二个比较好解决，只要编码表，解码表存储合理，这个问题就能很好解决，先来讲讲范式huffman，然后再说这个问题该怎么解决。

范式huffman编码也是前缀编码，最后的效果与huffman相同，但是编码却与huffman不同。

范式可以理解为公认的模式，也就是说范式huffman对数据的编码只有一种结果，这一点不同于huffman，而且范式huffman的编码结果是huffman无法得到的。

再次使用上面的例子来进行说明：

####编码长度

与huffman不同，范式huffman的第一步是求出每个字符的编码长度，但求解过程与huffman相似。这里采用bzip2的实现来讲解（使用bzip2的思想，实现并不完全相同），下面的图中省略了字符，只留下字符出现的频数。

如果数据中出现过的字符的数量为n，那么就使用一个长度为2n的数组，后面n个元素为个字符的频数，前面n个元素为以后面频数建立的最小堆，堆中的数据为索引，如下，分隔线之前为最小堆：

![](/images/数据压缩之编码器/heap1.png)

取出堆顶元素9，它代表索引为9的元素是最小的，即在频数中1是最小的，将9放到堆尾，调整堆，使它再次成为最小堆：

![](/images/数据压缩之编码器/heap2.png)

再取出堆顶元素，调整为最小堆：

![](/images/数据压缩之编码器/heap3.png)

这时将取出的两个元素对应的频数相加，即1 + 2 = 3，将其放入下标为5的位置，将下标为9和11内的元素改为5，表示它们的父亲为5，将下标为4的元素改为5，并将其插入堆中，如下：

![](/images/数据压缩之编码器/heap4.png)

上面的三个过程就是，取出两个最小值，再将他们的和和并为一个节点。
再来详细列出下一组操作：
![](/images/数据压缩之编码器/heap5.png)
![](/images/数据压缩之编码器/heap6.png)
![](/images/数据压缩之编码器/heap7.png)

重复上述操作，下面只列出每一步的结果：

![](/images/数据压缩之编码器/heap8.png)
![](/images/数据压缩之编码器/heap9.png)
![](/images/数据压缩之编码器/heap10.png)

到这里huffman树也就建立好了，其实这算是一个很特殊的树，因为无法遍历它，但是对于我们来说，这些信息已经足够求出编码长度了。
从树的叶子节点到树根的距离就是对应字符的编码长度，在这里树根为1，以叶子节点7为例，它的父亲节点为3，3的父亲节点为2，2的父亲节点为1，叶子节点对应的字符为b，那么b的编码长度就为3，按照这个方法，可以求出所以字符的编码:

![](/images/数据压缩之编码器/code.png)

####生成编码

先把最后生成的编码列出来在慢慢讲解：

![](/images/数据压缩之编码器/code2.png)

求解过程是这样的，先按编码长度排序，排序结果如上图所示。
a的编码长度为1，那么它的编码就为“0”，加1，就会得到下一个字符的编码，即“1”<br/>
然后是b，它的编码长度为3，可是“1”的长度不够，那就往后面补0，则它的编码为“100”，再加1，下一个字符的编码就是“101”<br/>
c的编码长度为3，那么编码就为“101”，下一个字符的编码为“110”<br/>
e的编码长度为3，那么编码就为“110”，下一个字符的编码为“111”<br/>
d的编码长度为4，不够，补0，则编码为“1110”，下一个字符的编码为“1111”<br/>
f的编码长度为4，那么它的编码就为“1111”<br/>


这样编码就完成了，范式huffman也就讲完了。

###一些优化方法

主要来说说编码表和解码表应该如何存储。

先说编码，在编码的过程中，我们要将字符转换为对应的二进制编码。
最简单的方法就是将每个字符的编码存储为字符串，然后再转为二进制，可是每个字符都要进行这样的操作，很显然这里的耗时会很多。
我们都很清楚，编码最后是以二进制的形式存储的，那么我们在存储编码表的时候也直接使用二进制存储不就很方便吗？可是，仔细想来，字符的编码最长可能长达255位，对这么长的二进制数据进行操作是很不方便的，而32位以下的二进制数据处理起来就会很简单，那么能不能减少最长编码长度呢？在bzip2中是这样处理的，只要最长编码长度大于某一限定值，那么就将所有字符的频数减半，重新计算编码。虽然在编码的计算上浪费了时间，编码也不再是最优的，压缩效果会降低，但是这些东西带来的损失在编码速度上带来的提升面前就算不上什么了。

再来说解码，朴素的huffman解码，一般都是一位一位进行判断，从树根到叶子节点，就找到了一个字符。
但是这里也要将每一位分离出来，再进行比较，可想而之，速度会很慢，原因见上文引用的那段话。
跟编码一样，我们不必分离出每一位，而是直接使用二进制数据进行解码。
在解码的过程中我们也要有一张编码表，然后我们来构造出一张解码表，可是各个字符的编码长度不同，解码表又如何构造呢？在编码的过程中我们限定了最长编码长度，那么在解码每次就读取限定值长度的数据，然后进行解码。由限定值长度的数据到字符，我们需要这样一个映射，那么很自然的，就建立这样一张表。在这张表中，所有有可能出现的数据都将对应一个字符。仍然以上面的数据进行举例，假如说最长编码长度限定为4，那么就应该建立如下的解码表：

![](/images/数据压缩之编码器/decode.png)

##算术编码

huffman编码一个缺点，那就是它的编码长度必须为整数，这也导致了它不能真能达到最优。尤其是当某以字符的频数非常大时，这种损失也很大。

而算术编码提供了另外一种思想，它依赖与预测模型，预测的越准，编码效果就越好。

而算术编码使用了另一种思想，既然会产生小数，那么就使用“小数”来编码，这里的小数并不是真正的小数，因为计算机存储浮点数有误差，我们又无法准确估计，所以用整数来表示小数。

先来举一个很简单的例子

    000000011

先使用huffman来对这段数据进行编码，0的编码为“0”，1的编码为“1”，编码结果为：

    0000 0001 1

###编码

来看一看算术编码的过程，特殊地（不一定要这样做，一般也不这样做），我们统计各字符的频数，然后用频数当作频率来进行预测。

在进行编码前，结果是未知的，我们将使用一个上限和一个下限，然后不管缩小范围，最终得到编码。
在这里我们就以字节为编码单位，那么在什么都不知道之前，上限就为255，下限就为0。

在对第一个字符进行编码之前，数据对于我们是未知的，那么就先进行预测，0出现的概率为7/9，1出现的概率为2/9，那么就要对0..255这个区间进行分割，就通过这两个概率，分为0..198和199..255两个区间。如果下一个数据为0，范围就会变为0..198，如果下一个数据为1，范围就会变为199..255。

我们来看第一个字符为0，那么范围变为了0..198。此时再次进行预测，分为两个区间0..154和155..198，知道第二个字符为0后，范围变为0..154。后面的使用同样的方式：

    0..119  120..154
    0  ->  0..119
    0..92   93..119
    0  ->  0..92
    0..71   72..92
    0  ->  0..71
    0..55   56..71
    0  ->  0..55
    0..42   43..55
    0  ->  0..42
    0..32   33..42
    1  ->  33..42
    33..40  41..42
    1  ->  41..42

到这里编码就完成了，41或42都可以作为编码的结果，我们发现这比huffman编码的结果少了一位，其实实际上算术编码的优势远不止这么点，因为这里使用了一个很简单的预测模型，如果使用高级的预测模型，算术编码的效果会很好。不扯这么远了，接着来看如何解码：就以42为例进行解码。

###解码

开始时范围还是0..255，还是将其分为两个区间0..198和199..255，我们发现42在前一个区间里，那么第一个字符就为0，现在范围变为了0..198。后面都一样：

    0..154   155..198
    42 -> 0..154 -> 0
    0..119   120..154
    42 -> 0..119 -> 0
    0..92    93..119
    42 -> 0..92  -> 0
    0..71    72..92
    42 -> 0..71  -> 0
    0..55    56..71
    42 -> 0..55  -> 0
    0..42    43..55
    42 -> 0..42  -> 0
    0..32    33..42
    42 -> 33..42 -> 1
    33..40   41..42
    42 -> 41..42 -> 1

到这里解码就结束了，其实算术编码讲到这里也就结束了。

##后记

很多人可能对huffman比较熟悉，所以写的也就比较多。算术编码的篇幅较少，大家理解其原理即可。
这章的东西不太感觉不太好讲，我讲的也很不好，大家能简单理解其原理就可以了，下一章会讲述预测模型。

这里给出了两个实现：

范式huffman：[https://github.com/liuyongkang/compress/blob/master/sample3/test.c][2]

算术编码：[https://github.com/liuyongkang/compress/blob/master/sample4/test.c][3]

[1]: http://hi.baidu.com/rodimus/item/3f61e235646950d66c15e9ef
[2]: https://github.com/liuyongkang/compress/blob/master/sample3/test.c
[3]: https://github.com/liuyongkang/compress/blob/master/sample4/test.c
