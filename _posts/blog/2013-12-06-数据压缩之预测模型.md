---
layout: post
title: 数据压缩之预测模型
description: 简单介绍预测模型，并说明DMC的原理
category: blog
tag: ['压缩', '预测模型', 'DMC', '马尔可夫']
---


##前言
上一章写的有些多了，其实本来不想牵扯太多实现的问题，但是大家应该都比较熟悉huffman，所以就多写了一点。这一章来讲预测模型，尽量讲清楚原理就好了。

##介绍
预测模型，一看这个名字大家就知道它是干什么的，就是在对数据进行编码前对其进行预测。但是这里的预测不是简单的预测接下来的数据是什么，而是对不同的数据给出其可能出现的概率，然后在进行编码。而且在很大程度上，预测模型的好坏会决定最后的编码效果。

我们知道，完全随机的序列是无法预测的。然而对于要压缩的文件来说，内容一般不可能是随机的，否则文件是没有意义的。一般的文件中，前面的出现过的数据，后面再次出现的概率会比其他数据大，这个道理大家应该都可以想明白，这也是进行数据压缩的一个基础。数据压缩本身就是基于统计学和概率论的，预测模型每次在预测后，都要对数据进行统计，以便在后面的预测中能达到更好的效果。

来说一个简单的预测模型吧，我把它叫做固定序列模型。假定预测的对象为字节，在对字节进行编码前，用它之前固定长度的一段序列来对后面这个字节进行预测。

比如说我们的压缩对象是一段英文，那么“the”这个单词出现的频率就会很高，假定我们用前两个字节来预测下一个字节。当预测模型第一次看到“th”时，由于此时还没有统计数据，那么可能出现的所有数据的概率都是相等的，对“e”进行编码后，预测模型会记录下“th”后面可能会出现“e”。后面又出现“the”时，预测模型遇到了“th”，它就知道后面出现“e”的可能性比其他字符大，完成编码后，会再次进行记录。

这个预测模型比较简单，理解起来也很容易，当然还有一些高级的预测模型，常用的有DMC,PPM,CTW。这里我打算介绍一下DMC。

##DMC

DMC的全称为动态马尔可夫压缩（Dynamic Markov compression），是一个使用了马尔可夫链的预测模型。

这里就不说马尔可夫链的标准定义了，简单来说，它就是一些序列，序列中的每个元素代表一个状态，每一个状态都可以转为其他的一些状态。

在预测模型中，每进行一次编码前都要根据目前的状态进行一次预测，编码后就会将对下一个数据进行预测，此时状态就会发生变化，进入下一个状态，进行又一次预测。这个过程使用马尔可夫链就显得非常合适，为了达到更好的效果，在状态转移时要根据情况对马尔可夫链进行一定的调整，所以这里成为动态马尔可夫压缩。

简单说以下DMC的具体过程。DMC进行预测的对象是bit，进行预测时并不是使用固定长度的前缀，而是前缀开始的地方为字节的边界。比如，对于一个字节的第一位进行预测时，使用它之前的8bits，对第二位进行预测时，使用它之前的9bits，对最后一位进行预测时，使用它之前的15位。为什么要这样做呢？我觉得把字节的边界作为起始位置比其他位置都要好，假如说使用定长的位数进行预测，对很多位进行预测时，就会使用之前某一字节的某几位，这对预测来说意义并不大，反而可能导致对预测结果产生不好的影响。使用之前的几个字节和该字节的前几位，感觉更合适，实际上也能达到更好的预测效果。

DMC中还有很重要的一点，就是对状态的调整。在马尔可夫链中，存在多个状态转换为同一个状态的情况，假如这多个转换都发生了，它们的预测情况应该互不相同，但是由于到达了同一个状态，预测情况就会相互影响，都无法达到应有的效果，所以这时就应该把这个状态分开，至于具体应该进行哪些操作，这里就不进行详细叙述了，大家能理解其基本原理就可以了。

##后记

虽然想讲的简单一点，但效果好像还是不理想。不过也没什么，稍微有个概念就行了。
下一章会介绍现在压缩软件中很流行的一类算法，字典压缩。


